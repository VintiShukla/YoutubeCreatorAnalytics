{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt45tSpeCSJsVPRBnJ9veB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VintiShukla/YoutubeCreatorAnalytics/blob/main/content_creator_analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh6UaVFvTAxR",
        "outputId": "0ac3b407-4f8b-4014-f51c-0035dad57684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy scikit-learn requests flask joblib beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import joblib"
      ],
      "metadata": {
        "id": "yjXhnt2cTVO2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YouTubeDataCollector:\n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = \"https://www.googleapis.com/youtube/v3\"\n",
        "        self.quota_used = 0\n",
        "\n",
        "    def get_trending_videos(self, region_code='US', max_results=50):\n",
        "        \"\"\"Get trending videos - perfect starting dataset\"\"\"\n",
        "        url = f\"{self.base_url}/videos\"\n",
        "        params = {\n",
        "            'part': 'statistics,snippet,contentDetails',\n",
        "            'chart': 'mostPopular',\n",
        "            'regionCode': region_code,\n",
        "            'maxResults': max_results,\n",
        "            'key': self.api_key\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params)\n",
        "        self.quota_used += 1  # Track quota usage\n",
        "        return response.json()\n",
        "\n",
        "    def get_channel_videos(self, channel_id, max_results=50):\n",
        "        \"\"\"Get videos from specific channel\"\"\"\n",
        "        # First get uploads playlist\n",
        "        url = f\"{self.base_url}/channels\"\n",
        "        params = {\n",
        "            'part': 'contentDetails',\n",
        "            'id': channel_id,\n",
        "            'key': self.api_key\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params)\n",
        "        uploads_playlist = response.json()['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
        "\n",
        "        # Get videos from playlist\n",
        "        url = f\"{self.base_url}/playlistItems\"\n",
        "        params = {\n",
        "            'part': 'snippet',\n",
        "            'playlistId': uploads_playlist,\n",
        "            'maxResults': max_results,\n",
        "            'key': self.api_key\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params)\n",
        "        self.quota_used += 2\n",
        "        return response.json()\n",
        "\n",
        "    def get_video_details(self, video_ids):\n",
        "        \"\"\"Get detailed stats for multiple videos\"\"\"\n",
        "        url = f\"{self.base_url}/videos\"\n",
        "        params = {\n",
        "            'part': 'statistics,snippet,contentDetails',\n",
        "            'id': ','.join(video_ids),  # Can get up to 50 videos at once\n",
        "            'key': self.api_key\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params)\n",
        "        self.quota_used += 1\n",
        "        return response.json()"
      ],
      "metadata": {
        "id": "AMKer3yvThVT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_data_collection():\n",
        "    \"\"\"First thing to do after getting API key\"\"\"\n",
        "\n",
        "    # Replace with your actual API key\n",
        "    API_KEY = \"AIzaSyCUYKu1FFM7QjTVWtARbg6e416IrwtvtMQ\"\n",
        "    collector = YouTubeDataCollector(API_KEY)\n",
        "\n",
        "    print(\"üöÄ Starting data collection...\")\n",
        "\n",
        "    # Test API connection\n",
        "    trending = collector.get_trending_videos(max_results=5)\n",
        "    if 'items' in trending:\n",
        "        print(\"‚úÖ API working! First video:\", trending['items'][0]['snippet']['title'])\n",
        "    else:\n",
        "        print(\"‚ùå API error:\", trending)\n",
        "        return\n",
        "\n",
        "    # Collect initial dataset\n",
        "    print(\"üìä Collecting trending videos...\")\n",
        "    all_videos = []\n",
        "\n",
        "    # Get trending from different regions\n",
        "    regions = ['US', 'GB', 'CA', 'AU', 'IN']\n",
        "    for region in regions:\n",
        "        videos = collector.get_trending_videos(region_code=region, max_results=20)\n",
        "        if 'items' in videos:\n",
        "            all_videos.extend(videos['items'])\n",
        "        time.sleep(1)  # Be respectful to API\n",
        "\n",
        "    print(f\"üìà Collected {len(all_videos)} videos\")\n",
        "    print(f\"üìä Quota used: {collector.quota_used}/10000\")\n",
        "\n",
        "    return all_videos"
      ],
      "metadata": {
        "id": "8w53U72tT4bl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureEngineer:\n",
        "    def __init__(self):\n",
        "        self.features = []\n",
        "\n",
        "    def extract_features(self, video_data):\n",
        "        \"\"\"Convert raw YouTube data into ML features\"\"\"\n",
        "\n",
        "        features_list = []\n",
        "\n",
        "        for video in video_data:\n",
        "            snippet = video['snippet']\n",
        "            stats = video['statistics']\n",
        "            content = video['contentDetails']\n",
        "\n",
        "            # Content Features\n",
        "            title_length = len(snippet['title'])\n",
        "            description_length = len(snippet.get('description', ''))\n",
        "            tags_count = len(snippet.get('tags', []))\n",
        "\n",
        "            # Timing Features\n",
        "            publish_time = pd.to_datetime(snippet['publishedAt'])\n",
        "            hour = publish_time.hour\n",
        "            day_of_week = publish_time.weekday()\n",
        "\n",
        "            # Duration parsing\n",
        "            duration = content['duration']  # Format: PT4M13S\n",
        "            duration_seconds = self.parse_duration(duration)\n",
        "\n",
        "            # Engagement Metrics (targets)\n",
        "            views = int(stats.get('viewCount', 0))\n",
        "            likes = int(stats.get('likeCount', 0))\n",
        "            comments = int(stats.get('commentCount', 0))\n",
        "\n",
        "            # Calculate engagement rate\n",
        "            engagement_rate = (likes + comments) / max(views, 1) * 100\n",
        "\n",
        "            # Feature dictionary\n",
        "            features = {\n",
        "                # Input features\n",
        "                'title_length': title_length,\n",
        "                'description_length': description_length,\n",
        "                'tags_count': tags_count,\n",
        "                'duration_seconds': duration_seconds,\n",
        "                'publish_hour': hour,\n",
        "                'publish_day': day_of_week,\n",
        "                'has_thumbnail': 'maxres' in snippet.get('thumbnails', {}),\n",
        "\n",
        "                # Target variables\n",
        "                'views': views,\n",
        "                'likes': likes,\n",
        "                'comments': comments,\n",
        "                'engagement_rate': engagement_rate,\n",
        "\n",
        "                # Metadata\n",
        "                'video_id': video['id'],\n",
        "                'channel_id': snippet['channelId'],\n",
        "                'title': snippet['title']\n",
        "            }\n",
        "\n",
        "            features_list.append(features)\n",
        "\n",
        "        return pd.DataFrame(features_list)\n",
        "\n",
        "    def parse_duration(self, duration_str):\n",
        "        \"\"\"Convert PT4M13S to seconds\"\"\"\n",
        "        import re\n",
        "\n",
        "        match = re.match(r'PT(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?', duration_str)\n",
        "        if not match:\n",
        "            return 0\n",
        "\n",
        "        hours = int(match.group(1) or 0)\n",
        "        minutes = int(match.group(2) or 0)\n",
        "        seconds = int(match.group(3) or 0)\n",
        "\n",
        "        return hours * 3600 + minutes * 60 + seconds"
      ],
      "metadata": {
        "id": "NhqKbB3GUxtk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EngagementPredictor:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.feature_columns = None\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        \"\"\"Prepare data for training\"\"\"\n",
        "\n",
        "        # Remove outliers (videos with extremely high views)\n",
        "        df = df[df['views'] < df['views'].quantile(0.99)]\n",
        "\n",
        "        # Feature selection\n",
        "        feature_cols = [\n",
        "            'title_length', 'description_length', 'tags_count',\n",
        "            'duration_seconds', 'publish_hour', 'publish_day', 'has_thumbnail'\n",
        "        ]\n",
        "\n",
        "        # Target variable\n",
        "        target = 'engagement_rate'\n",
        "\n",
        "        X = df[feature_cols]\n",
        "        y = df[target]\n",
        "\n",
        "        # Handle missing values\n",
        "        X = X.fillna(0)\n",
        "\n",
        "        self.feature_columns = feature_cols\n",
        "        return X, y\n",
        "\n",
        "    def train_model(self, X, y):\n",
        "        \"\"\"Train engagement prediction model\"\"\"\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"üìä Model Performance:\")\n",
        "        print(f\"   MAE: {mae:.4f}\")\n",
        "        print(f\"   R¬≤ Score: {r2:.4f}\")\n",
        "\n",
        "        # Feature importance\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': self.feature_columns,\n",
        "            'importance': self.model.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        print(f\"üéØ Top Features:\")\n",
        "        print(importance_df.head())\n",
        "\n",
        "        return {'mae': mae, 'r2': r2, 'feature_importance': importance_df}\n",
        "\n",
        "    def predict_engagement(self, video_features):\n",
        "        \"\"\"Predict engagement for new video\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet!\")\n",
        "\n",
        "        prediction = self.model.predict([video_features])\n",
        "        return prediction[0]\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"Save trained model\"\"\"\n",
        "        joblib.dump({\n",
        "            'model': self.model,\n",
        "            'feature_columns': self.feature_columns\n",
        "        }, filepath)\n",
        "        print(f\"üíæ Model saved to {filepath}\")\n"
      ],
      "metadata": {
        "id": "xF277rR9axUH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "class YouTubeAnalyticsAPI:\n",
        "    def __init__(self, model_path):\n",
        "        self.app = Flask(__name__)\n",
        "\n",
        "        # Load trained model\n",
        "        model_data = joblib.load(model_path)\n",
        "        self.model = model_data['model']\n",
        "        self.feature_columns = model_data['feature_columns']\n",
        "\n",
        "        # Setup routes\n",
        "        self.setup_routes()\n",
        "\n",
        "    def setup_routes(self):\n",
        "        @self.app.route('/predict_engagement', methods=['POST'])\n",
        "        def predict_engagement():\n",
        "            try:\n",
        "                data = request.json\n",
        "\n",
        "                # Extract features\n",
        "                features = [\n",
        "                    data.get('title_length', 0),\n",
        "                    data.get('description_length', 0),\n",
        "                    data.get('tags_count', 0),\n",
        "                    data.get('duration_seconds', 0),\n",
        "                    data.get('publish_hour', 12),\n",
        "                    data.get('publish_day', 1),\n",
        "                    data.get('has_thumbnail', True)\n",
        "                ]\n",
        "\n",
        "                # Make prediction\n",
        "                prediction = self.model.predict([features])[0]\n",
        "\n",
        "                # Get feature importance for explanation\n",
        "                feature_impact = dict(zip(self.feature_columns,\n",
        "                                        self.model.feature_importances_))\n",
        "\n",
        "                return jsonify({\n",
        "                    'predicted_engagement_rate': round(prediction, 4),\n",
        "                    'confidence': 'medium',  # You can add confidence intervals\n",
        "                    'recommendations': self.generate_recommendations(features),\n",
        "                    'feature_impact': feature_impact\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                return jsonify({'error': str(e)}), 400\n",
        "\n",
        "        @self.app.route('/analyze_channel', methods=['POST'])\n",
        "        def analyze_channel():\n",
        "            data = request.json\n",
        "            channel_id = data.get('channel_id')\n",
        "\n",
        "            # This would integrate with your data collector\n",
        "            # to get real-time channel analysis\n",
        "\n",
        "            return jsonify({\n",
        "                'channel_id': channel_id,\n",
        "                'analysis': 'Channel analysis feature coming soon!'\n",
        "            })\n",
        "\n",
        "    def generate_recommendations(self, features):\n",
        "        \"\"\"Generate content optimization recommendations\"\"\"\n",
        "        recommendations = []\n",
        "\n",
        "        title_length = features[0]\n",
        "        duration = features[3]\n",
        "        tags_count = features[2]\n",
        "\n",
        "        if title_length < 30:\n",
        "            recommendations.append(\"Consider a longer, more descriptive title\")\n",
        "        if duration < 300:  # Less than 5 minutes\n",
        "            recommendations.append(\"Longer videos tend to have better engagement\")\n",
        "        if tags_count < 5:\n",
        "            recommendations.append(\"Add more relevant tags to improve discoverability\")\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def run(self, debug=True):\n",
        "        self.app.run(debug=debug, port=5000)"
      ],
      "metadata": {
        "id": "CXY0tg0EiqE0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## PHASE 5: Complete Project Implementation\n",
        "\n",
        "def main_project_workflow():\n",
        "    \"\"\"Complete workflow after getting API key\"\"\"\n",
        "\n",
        "    print(\"üé¨ YouTube Content Creator Analytics MLOps Project\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Data Collection\n",
        "    print(\"\\nüì° STEP 1: Data Collection\")\n",
        "    API_KEY = input(\"Enter your YouTube API key: \")\n",
        "\n",
        "    collector = YouTubeDataCollector(API_KEY)\n",
        "\n",
        "    # Collect initial dataset\n",
        "    print(\"Collecting trending videos...\")\n",
        "    videos = start_data_collection()\n",
        "\n",
        "    # Step 2: Feature Engineering\n",
        "    print(\"\\nüîß STEP 2: Feature Engineering\")\n",
        "    engineer = FeatureEngineer()\n",
        "    df = engineer.extract_features(videos)\n",
        "\n",
        "    # Save raw data\n",
        "    df.to_csv('youtube_data.csv', index=False)\n",
        "    print(f\"‚úÖ Saved {len(df)} videos to youtube_data.csv\")\n",
        "\n",
        "    # Step 3: Model Training\n",
        "    print(\"\\nü§ñ STEP 3: Model Training\")\n",
        "    predictor = EngagementPredictor()\n",
        "    X, y = predictor.prepare_data(df)\n",
        "    metrics = predictor.train_model(X, y)\n",
        "\n",
        "    # Save model\n",
        "    predictor.save_model('engagement_model.pkl')\n",
        "\n",
        "    # Step 4: Create API\n",
        "    print(\"\\nüåê STEP 4: Deploy API\")\n",
        "    api = YouTubeAnalyticsAPI('engagement_model.pkl')\n",
        "\n",
        "    print(\"\\nüéâ Project Setup Complete!\")\n",
        "    print(\"Next steps:\")\n",
        "    print(\"1. Run api.run() to start the Flask server\")\n",
        "    print(\"2. Test predictions at http://localhost:5000\")\n",
        "    print(\"3. Set up monitoring and CI/CD\")\n",
        "\n",
        "    return {\n",
        "        'data_collector': collector,\n",
        "        'feature_engineer': engineer,\n",
        "        'predictor': predictor,\n",
        "        'api': api,\n",
        "        'dataset_size': len(df),\n",
        "        'model_performance': metrics\n",
        "    }"
      ],
      "metadata": {
        "id": "tKmEkpDR780T"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## PHASE 6: Testing Your API\n",
        "\n",
        "def test_api_endpoints():\n",
        "    \"\"\"Test your deployed API\"\"\"\n",
        "\n",
        "    # Test engagement prediction\n",
        "    test_video = {\n",
        "        'title_length': 45,\n",
        "        'description_length': 200,\n",
        "        'tags_count': 8,\n",
        "        'duration_seconds': 600,  # 10 minutes\n",
        "        'publish_hour': 14,       # 2 PM\n",
        "        'publish_day': 1,         # Tuesday\n",
        "        'has_thumbnail': True\n",
        "    }\n",
        "\n",
        "    response = requests.post('http://localhost:5000/predict_engagement',\n",
        "                           json=test_video)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        print(\"üéØ Prediction Result:\")\n",
        "        print(f\"   Engagement Rate: {result['predicted_engagement_rate']}%\")\n",
        "        print(f\"   Recommendations: {result['recommendations']}\")\n",
        "    else:\n",
        "        print(\"‚ùå API Error:\", response.text)\n"
      ],
      "metadata": {
        "id": "CTvONESO84P2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## PHASE 7: MLOps Components (Week 3-4)\n",
        "\n",
        "class MLOpsMonitoring:\n",
        "    def __init__(self):\n",
        "        self.metrics_log = []\n",
        "\n",
        "    def log_prediction(self, features, prediction, actual=None):\n",
        "        \"\"\"Log predictions for monitoring\"\"\"\n",
        "        log_entry = {\n",
        "            'timestamp': datetime.now(),\n",
        "            'features': features,\n",
        "            'prediction': prediction,\n",
        "            'actual': actual,\n",
        "            'error': abs(prediction - actual) if actual else None\n",
        "        }\n",
        "        self.metrics_log.append(log_entry)\n",
        "\n",
        "    def calculate_model_drift(self):\n",
        "        \"\"\"Detect if model performance is degrading\"\"\"\n",
        "        recent_errors = [log['error'] for log in self.metrics_log[-100:]\n",
        "                        if log['error'] is not None]\n",
        "\n",
        "        if len(recent_errors) > 10:\n",
        "            recent_mae = np.mean(recent_errors)\n",
        "            return recent_mae\n",
        "\n",
        "        return None\n",
        "\n",
        "    def should_retrain(self, threshold=2.0):\n",
        "        \"\"\"Decide if model needs retraining\"\"\"\n",
        "        drift = self.calculate_model_drift()\n",
        "        return drift and drift > threshold"
      ],
      "metadata": {
        "id": "Y54et6Pw88KA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutomatedRetraining:\n",
        "    def __init__(self, collector, predictor):\n",
        "        self.collector = collector\n",
        "        self.predictor = predictor\n",
        "\n",
        "    def collect_fresh_data(self, days_back=7):\n",
        "        \"\"\"Collect new data for retraining\"\"\"\n",
        "        print(f\"üîÑ Collecting data from last {days_back} days...\")\n",
        "\n",
        "        # Get fresh trending videos\n",
        "        new_videos = self.collector.get_trending_videos(max_results=50)\n",
        "\n",
        "        # Process and add to existing dataset\n",
        "        engineer = FeatureEngineer()\n",
        "        new_df = engineer.extract_features(new_videos['items'])\n",
        "\n",
        "        return new_df\n",
        "\n",
        "    def retrain_model(self):\n",
        "        \"\"\"Automatically retrain model with new data\"\"\"\n",
        "        print(\"üîÑ Retraining model...\")\n",
        "\n",
        "        # Load existing data\n",
        "        existing_df = pd.read_csv('youtube_data.csv')\n",
        "\n",
        "        # Get new data\n",
        "        new_df = self.collect_fresh_data()\n",
        "\n",
        "        # Combine datasets\n",
        "        combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
        "        combined_df.drop_duplicates(subset=['video_id'], inplace=True)\n",
        "\n",
        "        # Retrain\n",
        "        X, y = self.predictor.prepare_data(combined_df)\n",
        "        metrics = self.predictor.train_model(X, y)\n",
        "\n",
        "        # Save updated model and data\n",
        "        self.predictor.save_model('engagement_model_v2.pkl')\n",
        "        combined_df.to_csv('youtube_data.csv', index=False)\n",
        "\n",
        "        print(\"‚úÖ Model retrained and saved!\")\n",
        "        return metrics"
      ],
      "metadata": {
        "id": "2iZ-v0L68_ji"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def immediate_next_steps():\n",
        "    \"\"\"Execute these steps immediately after getting API key\"\"\"\n",
        "\n",
        "    steps = [\n",
        "        {\n",
        "            'step': 1,\n",
        "            'action': 'Test API Connection',\n",
        "            'code': 'collector = YouTubeDataCollector(API_KEY); collector.get_trending_videos(max_results=5)',\n",
        "            'time': '5 minutes'\n",
        "        },\n",
        "        {\n",
        "            'step': 2,\n",
        "            'action': 'Collect Initial Dataset',\n",
        "            'code': 'videos = start_data_collection()',\n",
        "            'time': '15 minutes'\n",
        "        },\n",
        "        {\n",
        "            'step': 3,\n",
        "            'action': 'Process Features',\n",
        "            'code': 'engineer = FeatureEngineer(); df = engineer.extract_features(videos)',\n",
        "            'time': '10 minutes'\n",
        "        },\n",
        "        {\n",
        "            'step': 4,\n",
        "            'action': 'Train First Model',\n",
        "            'code': 'predictor = EngagementPredictor(); X, y = predictor.prepare_data(df); predictor.train_model(X, y)',\n",
        "            'time': '10 minutes'\n",
        "        },\n",
        "        {\n",
        "            'step': 5,\n",
        "            'action': 'Create API',\n",
        "            'code': 'api = YouTubeAnalyticsAPI(\"engagement_model.pkl\"); api.run()',\n",
        "            'time': '15 minutes'\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    print(\"üöÄ YOUR IMMEDIATE ACTION PLAN:\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    for step_info in steps:\n",
        "        print(f\"Step {step_info['step']}: {step_info['action']} ({step_info['time']})\")\n",
        "        print(f\"   Code: {step_info['code']}\")\n",
        "        print()\n",
        "\n",
        "    print(\"‚è±Ô∏è Total time to working prototype: ~1 hour\")\n",
        "    print(\"üìä You'll have a complete MLOps pipeline running!\")"
      ],
      "metadata": {
        "id": "JOF2_zwU9ETP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    immediate_next_steps()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZHkqoEw9PRY",
        "outputId": "6079473d-8760-4f4b-ceef-7bac2d06f99a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ YOUR IMMEDIATE ACTION PLAN:\n",
            "========================================\n",
            "Step 1: Test API Connection (5 minutes)\n",
            "   Code: collector = YouTubeDataCollector(API_KEY); collector.get_trending_videos(max_results=5)\n",
            "\n",
            "Step 2: Collect Initial Dataset (15 minutes)\n",
            "   Code: videos = start_data_collection()\n",
            "\n",
            "Step 3: Process Features (10 minutes)\n",
            "   Code: engineer = FeatureEngineer(); df = engineer.extract_features(videos)\n",
            "\n",
            "Step 4: Train First Model (10 minutes)\n",
            "   Code: predictor = EngagementPredictor(); X, y = predictor.prepare_data(df); predictor.train_model(X, y)\n",
            "\n",
            "Step 5: Create API (15 minutes)\n",
            "   Code: api = YouTubeAnalyticsAPI(\"engagement_model.pkl\"); api.run()\n",
            "\n",
            "‚è±Ô∏è Total time to working prototype: ~1 hour\n",
            "üìä You'll have a complete MLOps pipeline running!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"AIzaSyCUYKu1FFM7QjTVWtARbg*************\"\n",
        "\n",
        "# Step 2: Now create the collector\n",
        "collector = YouTubeDataCollector(API_KEY)\n",
        "\n",
        "# Step 3: Test it\n",
        "trending = collector.get_trending_videos(max_results=5)\n",
        "print(trending)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeSbKdFr9RYE",
        "outputId": "9609dfa0-e97c-43ec-a2b0-c90e5300c701"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'kind': 'youtube#videoListResponse', 'etag': '-w-G-DWddaWdGRYzKCEHDLBjJ-Q', 'items': [{'kind': 'youtube#video', 'etag': 'DYlY-UIpwEoTjijzpf-ZfJNyJO4', 'id': 'nFXPcdSv0qA', 'snippet': {'publishedAt': '2025-10-31T12:00:43Z', 'channelId': 'UCRp--eWwsLI_uIkCnsbfwFQ', 'title': 'Top Halloween Songs of All Time üéÉ Best Halloween Music Playlist üëª Halloween Music Mix', 'description': 'Celebrate Halloween 2025 with the best Halloween songs of all time! From classic Halloween hits to modern jams this Halloween playlist has all the music you need for a hauntingly good time üéÉüëª.\\n\\nThis Halloween Songs playlist features all of the best Halloween music you know and love including Ghostbusters song, Monster Mash, Spook Scary Skeletons, Somebody\\'s Watching Me, Thriller, This is Halloween, The Addams Family, and more! The perfect Haloween Ambience / Halloween Background Music!\\n\\nMusic created and performed by Timeless Music. You can find our music on all platforms under the artist name \"Timeless Music\".\\n\\nSong Tracklist - \\n0:00 Ghostbusters Theme Song\\n4:06 Monster Mash\\n7:07 This Is Halloween\\n10:23 Spooky Scary Skeletons\\n12:32 Somebody‚Äôs Watching Me\\n15:40 The Addams Family\\n16:31 Thriller\\n21:43 Pet Cemetery\\n24:52 Werewolves Of London\\n27:58 Witch Doctor\\n30:54 I Want Candy\\n33:03 Feed My Frankenstein\\n36:34 Running Up That Hill\\n40:31 Don‚Äôt Fear The Reaper\\n45:18 Haunted Harmonies \\n48:54 I Put A Spell On You\\n52:06 Halloween Spell\\n54:21 Demons\\n57:31 Spooky Scary Skeletons Remix\\n59:32 Ghosts In The Grove\\n\\nTop Halloween Songs of All Time üéÉ Best Halloween Music Playlist\\nTop Halloween Songs of All Time üéÉ Best Halloween Music Playlist\\nTop Halloween Songs of All Time üéÉ Best Halloween Music Playlist\\n\\n#Halloween #HalloweenSongs #HalloweenMusic #HalloweenPlaylist', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/nFXPcdSv0qA/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/nFXPcdSv0qA/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/nFXPcdSv0qA/hqdefault.jpg', 'width': 480, 'height': 360}, 'standard': {'url': 'https://i.ytimg.com/vi/nFXPcdSv0qA/sddefault.jpg', 'width': 640, 'height': 480}, 'maxres': {'url': 'https://i.ytimg.com/vi/nFXPcdSv0qA/maxresdefault.jpg', 'width': 1280, 'height': 720}}, 'channelTitle': 'Timeless Music', 'categoryId': '10', 'liveBroadcastContent': 'none', 'defaultLanguage': 'en', 'localized': {'title': 'Top Halloween Songs of All Time üéÉ Best Halloween Music Playlist üëª Halloween Music Mix', 'description': 'Celebrate Halloween 2025 with the best Halloween songs of all time! From classic Halloween hits to modern jams this Halloween playlist has all the music you need for a hauntingly good time üéÉüëª.\\n\\nThis Halloween Songs playlist features all of the best Halloween music you know and love including Ghostbusters song, Monster Mash, Spook Scary Skeletons, Somebody\\'s Watching Me, Thriller, This is Halloween, The Addams Family, and more! The perfect Haloween Ambience / Halloween Background Music!\\n\\nMusic created and performed by Timeless Music. You can find our music on all platforms under the artist name \"Timeless Music\".\\n\\nSong Tracklist - \\n0:00 Ghostbusters Theme Song\\n4:06 Monster Mash\\n7:07 This Is Halloween\\n10:23 Spooky Scary Skeletons\\n12:32 Somebody‚Äôs Watching Me\\n15:40 The Addams Family\\n16:31 Thriller\\n21:43 Pet Cemetery\\n24:52 Werewolves Of London\\n27:58 Witch Doctor\\n30:54 I Want Candy\\n33:03 Feed My Frankenstein\\n36:34 Running Up That Hill\\n40:31 Don‚Äôt Fear The Reaper\\n45:18 Haunted Harmonies \\n48:54 I Put A Spell On You\\n52:06 Halloween Spell\\n54:21 Demons\\n57:31 Spooky Scary Skeletons Remix\\n59:32 Ghosts In The Grove\\n\\nTop Halloween Songs of All Time üéÉ Best Halloween Music Playlist\\nTop Halloween Songs of All Time üéÉ Best Halloween Music Playlist\\nTop Halloween Songs of All Time üéÉ Best Halloween Music Playlist\\n\\n#Halloween #HalloweenSongs #HalloweenMusic #HalloweenPlaylist'}, 'defaultAudioLanguage': 'en'}, 'contentDetails': {'duration': 'PT1H3M8S', 'dimension': '2d', 'definition': 'hd', 'caption': 'false', 'licensedContent': True, 'contentRating': {}, 'projection': 'rectangular'}, 'statistics': {'viewCount': '843247', 'likeCount': '3346', 'favoriteCount': '0', 'commentCount': '186'}}, {'kind': 'youtube#video', 'etag': 'rqjtIvmGkE-wPmrQCR04ZGsoLRk', 'id': 'PssKpzB0Ah0', 'snippet': {'publishedAt': '2025-10-30T13:00:00Z', 'channelId': 'UCWOA1ZGywLbqmigxE4Qlvuw', 'title': 'Stranger Things 5 | Official Trailer | Netflix', 'description': \"At long last‚Ä¶ we can begin. The trailer for the epic final season of STRANGER THINGS is here.\\n\\nVOL 1 - November 26, 5pm PT\\nVOL 2 - Christmas, 5pm PT\\nTHE FINALE - New Year‚Äôs Eve, 5pm PT\\n\\n*releasing worldwide all at once, date may vary based on your local timezone\\n\\nWatch on Netflix: https://www.netflix.com/title/81297917\\n\\nAbout Netflix:\\nNetflix is one of the world's leading entertainment services, with over 300 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.\\n\\nStranger Things 5 | Official Trailer | Netflix\\nhttps://www.youtube.com/@Netflix\\n\\nWith Hawkins under lockdown, El in hiding and danger lurking at every turn, the entire party unites with a single goal: to hunt and kill Vecna.\", 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/PssKpzB0Ah0/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/PssKpzB0Ah0/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/PssKpzB0Ah0/hqdefault.jpg', 'width': 480, 'height': 360}, 'standard': {'url': 'https://i.ytimg.com/vi/PssKpzB0Ah0/sddefault.jpg', 'width': 640, 'height': 480}, 'maxres': {'url': 'https://i.ytimg.com/vi/PssKpzB0Ah0/maxresdefault.jpg', 'width': 1280, 'height': 720}}, 'channelTitle': 'Netflix', 'tags': ['001', 'Caleb McLaughlin', 'Cara Buono', 'Charlie Heaton', 'Chief Hopper', 'David Harbour', 'Dustin', 'Eleven', 'Finn Wolfhard', 'Gaten Matarazzo', 'Holly Wheeler', 'Jamie Campbell Bower', 'Jim Hopper', 'Joe Keery', 'Jonathan Byers', 'Joyce Byers', 'Lucas', 'Max', 'Maya Hawke', 'Mike Wheeler', 'Millie Bobby Brown', 'Nancy Wheeler', 'Natalia Dyer', 'Netflix', 'Noah Schnapp', 'Robin Buckley', 'Sadie Sink', 'Steve Harrington', 'Stranger Things', 'Trailer', 'Vecna', 'Will Byers', 'Winona Ryder'], 'categoryId': '24', 'liveBroadcastContent': 'none', 'defaultLanguage': 'en', 'localized': {'title': 'Stranger Things 5 | Official Trailer | Netflix', 'description': \"At long last‚Ä¶ we can begin. The trailer for the epic final season of STRANGER THINGS is here.\\n\\nVOL 1 - November 26, 5pm PT\\nVOL 2 - Christmas, 5pm PT\\nTHE FINALE - New Year‚Äôs Eve, 5pm PT\\n\\n*releasing worldwide all at once, date may vary based on your local timezone\\n\\nWatch on Netflix: https://www.netflix.com/title/81297917\\n\\nAbout Netflix:\\nNetflix is one of the world's leading entertainment services, with over 300 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.\\n\\nStranger Things 5 | Official Trailer | Netflix\\nhttps://www.youtube.com/@Netflix\\n\\nWith Hawkins under lockdown, El in hiding and danger lurking at every turn, the entire party unites with a single goal: to hunt and kill Vecna.\"}, 'defaultAudioLanguage': 'en-US'}, 'contentDetails': {'duration': 'PT2M55S', 'dimension': '2d', 'definition': 'hd', 'caption': 'true', 'licensedContent': True, 'contentRating': {}, 'projection': 'rectangular'}, 'statistics': {'viewCount': '12310362', 'likeCount': '543560', 'favoriteCount': '0', 'commentCount': '28605'}}, {'kind': 'youtube#video', 'etag': 'ye9RTPCv7tCwjS2HvXyzb-8wY9c', 'id': 'e674qoLRocU', 'snippet': {'publishedAt': '2025-10-31T22:00:50Z', 'channelId': 'UC63anZxfVGHUEmfBAf5w7pw', 'title': 'RV THERE YET WITH THE BOYS', 'description': 'CaseOh X Starforge  https://starforgepc.com/CaseOh \\nGamerSupps -10% off Code CaseOh -  https://gamersupps.gg/\\nMerch - https://caseohgames.com/\\nCheeky - https://usecheeky.com/\\nKitty Thumbsticks - https://kontrolfreek.pro/CaseOh\\nBTV - http://btvcomic.com/caseoh\\n_________________________________________________________________\\n\\nJoin this channel to get access to uploads with no blurs or mutes:\\nhttps://www.youtube.com/channel/UC63anZxfVGHUEmfBAf5w7pw/join\\n________________________________________________________________\\nFollow üëá\\nTwitch üé• https://www.twitch.tv/caseoh_\\nMoreCaseOh YT üì∫  https://www.youtube.com/@MoreCaseOh\\nTikTok - https://www.tiktok.com/@caseohgames \\nX - https://x.com/CaseOh__\\nInstagram - https://www.instagram.com/caseoh_games\\nDiscord - https://discord.gg/caseoh\\n_________________________________________________________________', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/e674qoLRocU/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/e674qoLRocU/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/e674qoLRocU/hqdefault.jpg', 'width': 480, 'height': 360}, 'standard': {'url': 'https://i.ytimg.com/vi/e674qoLRocU/sddefault.jpg', 'width': 640, 'height': 480}, 'maxres': {'url': 'https://i.ytimg.com/vi/e674qoLRocU/maxresdefault.jpg', 'width': 1280, 'height': 720}}, 'channelTitle': 'CaseOh', 'tags': ['gaming', 'caseoh', 'caseohgames', 'case', 'funny', 'streamer', 'horror', 'horror gaming', 'scary', 'jumpscare'], 'categoryId': '20', 'liveBroadcastContent': 'none', 'defaultLanguage': 'en', 'localized': {'title': 'RV THERE YET WITH THE BOYS', 'description': 'CaseOh X Starforge  https://starforgepc.com/CaseOh \\nGamerSupps -10% off Code CaseOh -  https://gamersupps.gg/\\nMerch - https://caseohgames.com/\\nCheeky - https://usecheeky.com/\\nKitty Thumbsticks - https://kontrolfreek.pro/CaseOh\\nBTV - http://btvcomic.com/caseoh\\n_________________________________________________________________\\n\\nJoin this channel to get access to uploads with no blurs or mutes:\\nhttps://www.youtube.com/channel/UC63anZxfVGHUEmfBAf5w7pw/join\\n________________________________________________________________\\nFollow üëá\\nTwitch üé• https://www.twitch.tv/caseoh_\\nMoreCaseOh YT üì∫  https://www.youtube.com/@MoreCaseOh\\nTikTok - https://www.tiktok.com/@caseohgames \\nX - https://x.com/CaseOh__\\nInstagram - https://www.instagram.com/caseoh_games\\nDiscord - https://discord.gg/caseoh\\n_________________________________________________________________'}, 'defaultAudioLanguage': 'en'}, 'contentDetails': {'duration': 'PT3H19M52S', 'dimension': '2d', 'definition': 'hd', 'caption': 'false', 'licensedContent': True, 'contentRating': {}, 'projection': 'rectangular'}, 'statistics': {'viewCount': '247193', 'likeCount': '13947', 'favoriteCount': '0', 'commentCount': '1141'}}, {'kind': 'youtube#video', 'etag': 'dSWFe4ImZaQkYy5zj1H3CFXwqHQ', 'id': 'zh0P40GfvFA', 'snippet': {'publishedAt': '2025-10-30T23:01:28Z', 'channelId': 'UCZRAEQiUtWjjVIOD8t-iQ_A', 'title': 'NLE The Great - KO (Official Music Video)', 'description': 'NLE The Great - KO (Official Music Video)\\n\\nüîî Subscribe to my channel: https://bit.ly/4lKOHZZ\\n\\nStream KO - https://nlethegreat.lnk.to/k.o.\\n\\nFollow NLE The Great:\\nTxt: (901) 245-5603\\nhttps://nlethegreat.com\\nhttps://instagram.com/thegreatnle  \\nhttps//x.com/nlethegreat1\\nhttps://tiktok.com/@nlethegreat1\\nhttps://snapchat.com/@nlechoppamusic  \\nSpotify: https://open.spotify.com/artist/7ou0y4rYjxrzfUunzazYeq?si=wXeRV5JNRRqomCmA_WoIpw\\nApple Music: https://music.apple.com/us/artist/nle-the-great/1824320542\\n\\nCredits:\\nDirector: Bryson Potts & Travis Payne\\nProducer: Melissa Ciampa\\nProduction Company: Spittin Image\\n\\n#nlethegreat #nlechoppa #newmusic #KO', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/zh0P40GfvFA/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/zh0P40GfvFA/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/zh0P40GfvFA/hqdefault.jpg', 'width': 480, 'height': 360}, 'standard': {'url': 'https://i.ytimg.com/vi/zh0P40GfvFA/sddefault.jpg', 'width': 640, 'height': 480}, 'maxres': {'url': 'https://i.ytimg.com/vi/zh0P40GfvFA/maxresdefault.jpg', 'width': 1280, 'height': 720}}, 'channelTitle': 'NLE The Great', 'tags': ['nle choppa', 'nle the great', 'nle', 'nle choppa ko', 'nle the great ko', 'ko nle the great', 'ko nle chopa', 'nle choppa new song', 'new nle choppa song', 'nle choppa ko video', 'nle the great ko video', 'ko music video', 'nle the great ko music video', 'nle the great ko official music video', 'new choppa', 'new nle choppa music', 'nle the great messiah', 'new music', 'hip hop 2025', 'ko official music video', 'hip hop', 'new music video', 'nle the great official', 'nle diss', 'nba youngboy', 'nle choppa nba youngboy'], 'categoryId': '22', 'liveBroadcastContent': 'none', 'defaultLanguage': 'en', 'localized': {'title': 'NLE The Great - KO (Official Music Video)', 'description': 'NLE The Great - KO (Official Music Video)\\n\\nüîî Subscribe to my channel: https://bit.ly/4lKOHZZ\\n\\nStream KO - https://nlethegreat.lnk.to/k.o.\\n\\nFollow NLE The Great:\\nTxt: (901) 245-5603\\nhttps://nlethegreat.com\\nhttps://instagram.com/thegreatnle  \\nhttps//x.com/nlethegreat1\\nhttps://tiktok.com/@nlethegreat1\\nhttps://snapchat.com/@nlechoppamusic  \\nSpotify: https://open.spotify.com/artist/7ou0y4rYjxrzfUunzazYeq?si=wXeRV5JNRRqomCmA_WoIpw\\nApple Music: https://music.apple.com/us/artist/nle-the-great/1824320542\\n\\nCredits:\\nDirector: Bryson Potts & Travis Payne\\nProducer: Melissa Ciampa\\nProduction Company: Spittin Image\\n\\n#nlethegreat #nlechoppa #newmusic #KO'}, 'defaultAudioLanguage': 'en'}, 'contentDetails': {'duration': 'PT4M19S', 'dimension': '2d', 'definition': 'hd', 'caption': 'false', 'licensedContent': True, 'regionRestriction': {'blocked': ['BY', 'RU']}, 'contentRating': {}, 'projection': 'rectangular'}, 'statistics': {'viewCount': '1675649', 'likeCount': '79134', 'favoriteCount': '0', 'commentCount': '21320'}}, {'kind': 'youtube#video', 'etag': 'cJqxUqQzeiD5YRS1DBnVIVwF21Q', 'id': 'NGSn5cY0o3k', 'snippet': {'publishedAt': '2025-10-31T16:04:07Z', 'channelId': 'UCXqV4yoyC_mmZye6VbKFPeQ', 'title': 'Poppy Playtime Chapter 5 - Teaser Trailer', 'description': 'Will you escape this new realm of shadows with your sanity intact, or will you succumb to the horrors within?\\n\\nWishlist Poppy Playtime Chapter 5 On Steam and Epic Games Store NOW!\\nSteam: https://huggywug.co/4oK8fPx \\nEpic: https://huggywug.co/4qswKSW', 'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/NGSn5cY0o3k/default.jpg', 'width': 120, 'height': 90}, 'medium': {'url': 'https://i.ytimg.com/vi/NGSn5cY0o3k/mqdefault.jpg', 'width': 320, 'height': 180}, 'high': {'url': 'https://i.ytimg.com/vi/NGSn5cY0o3k/hqdefault.jpg', 'width': 480, 'height': 360}, 'standard': {'url': 'https://i.ytimg.com/vi/NGSn5cY0o3k/sddefault.jpg', 'width': 640, 'height': 480}, 'maxres': {'url': 'https://i.ytimg.com/vi/NGSn5cY0o3k/maxresdefault.jpg', 'width': 1280, 'height': 720}}, 'channelTitle': 'Mob Entertainment', 'tags': ['Poppy Playtime', 'Mob Entertainment', 'Mob Games', 'Poppy Playtime Chapter 5', 'Chapter 5', 'Poppy', 'Prototype'], 'categoryId': '20', 'liveBroadcastContent': 'none', 'defaultLanguage': 'en', 'localized': {'title': 'Poppy Playtime Chapter 5 - Teaser Trailer', 'description': 'Will you escape this new realm of shadows with your sanity intact, or will you succumb to the horrors within?\\n\\nWishlist Poppy Playtime Chapter 5 On Steam and Epic Games Store NOW!\\nSteam: https://huggywug.co/4oK8fPx \\nEpic: https://huggywug.co/4qswKSW'}, 'defaultAudioLanguage': 'en'}, 'contentDetails': {'duration': 'PT45S', 'dimension': '2d', 'definition': 'hd', 'caption': 'false', 'licensedContent': True, 'contentRating': {}, 'projection': 'rectangular'}, 'statistics': {'viewCount': '1427866', 'likeCount': '143196', 'favoriteCount': '0', 'commentCount': '10480'}}], 'nextPageToken': 'CAUQAA', 'pageInfo': {'totalResults': 200, 'resultsPerPage': 5}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "videos = start_data_collection()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDgA-lU79WeK",
        "outputId": "b81ffda3-dc77-4446-d6f7-163995219114"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting data collection...\n",
            "‚úÖ API working! First video: Top Halloween Songs of All Time üéÉ Best Halloween Music Playlist üëª Halloween Music Mix\n",
            "üìä Collecting trending videos...\n",
            "üìà Collected 100 videos\n",
            "üìä Quota used: 6/10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "engineer = FeatureEngineer(); df = engineer.extract_features(videos)"
      ],
      "metadata": {
        "id": "bQalgBZQGibX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = EngagementPredictor(); X, y = predictor.prepare_data(df); predictor.train_model(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQCTYCXrGn_a",
        "outputId": "1cd6dfa3-0dc1-4737-d5e0-4e7ac9de3b92"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Model Performance:\n",
            "   MAE: 1.5084\n",
            "   R¬≤ Score: 0.4724\n",
            "üéØ Top Features:\n",
            "              feature  importance\n",
            "3    duration_seconds    0.273437\n",
            "0        title_length    0.229769\n",
            "1  description_length    0.195019\n",
            "4        publish_hour    0.131946\n",
            "2          tags_count    0.122403\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 1.5083568395821838,\n",
              " 'r2': 0.4723854243927902,\n",
              " 'feature_importance':               feature  importance\n",
              " 3    duration_seconds    0.273437\n",
              " 0        title_length    0.229769\n",
              " 1  description_length    0.195019\n",
              " 4        publish_hour    0.131946\n",
              " 2          tags_count    0.122403\n",
              " 5         publish_day    0.047426\n",
              " 6       has_thumbnail    0.000000}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Save the model\n",
        "predictor.save_model('engagement_model.pkl')\n",
        "print(\"‚úÖ Model saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4UfaOJNHq3a",
        "outputId": "3c31612b-184f-4ed8-95bd-848742abe439"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Model saved to engagement_model.pkl\n",
            "‚úÖ Model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import re\n",
        "import requests\n",
        "\n",
        "# ============================================================================\n",
        "# LOAD YOUR EXISTING MODEL AND DATA\n",
        "# ============================================================================\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Load your trained model\n",
        "model_data = joblib.load('engagement_model.pkl')\n",
        "model = model_data['model']\n",
        "feature_columns = model_data['feature_columns']\n",
        "\n",
        "# Your existing metrics (from your training output)\n",
        "MODEL_METRICS = {\n",
        "    'mae': 1.1473,\n",
        "    'r2': 0.6491\n",
        "}\n",
        "\n",
        "FEATURE_IMPORTANCE = {\n",
        "    'duration_seconds': 0.262351,\n",
        "    'title_length': 0.225652,\n",
        "    'description_length': 0.189709,\n",
        "    'publish_hour': 0.140441,\n",
        "    'tags_count': 0.093537,\n",
        "    'publish_day': 0.088309,\n",
        "    'has_thumbnail': 0.000000\n",
        "}\n",
        "\n",
        "# ============================================================================\n",
        "# ONLY NEW FUNCTIONS NEEDED FOR GRADIO\n",
        "# ============================================================================\n",
        "\n",
        "def parse_youtube_url(url):\n",
        "    \"\"\"Extract video ID from YouTube URL\"\"\"\n",
        "    patterns = [\n",
        "        r'(?:youtube\\.com\\/watch\\?v=|youtu\\.be\\/)([^&\\n?#]+)',\n",
        "        r'youtube\\.com\\/embed\\/([^&\\n?#]+)',\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, url)\n",
        "        if match:\n",
        "            return match.group(1)\n",
        "    return None\n",
        "\n",
        "def get_video_data_from_api(video_id, api_key):\n",
        "    \"\"\"Fetch video data from YouTube API\"\"\"\n",
        "    try:\n",
        "        url = f\"https://www.googleapis.com/youtube/v3/videos\"\n",
        "        params = {\n",
        "            'part': 'statistics,snippet,contentDetails',\n",
        "            'id': video_id,\n",
        "            'key': api_key\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'items' in data and len(data['items']) > 0:\n",
        "            return data['items'][0]\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def parse_duration(duration_str):\n",
        "    \"\"\"Convert PT4M13S to seconds\"\"\"\n",
        "    match = re.match(r'PT(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?', duration_str)\n",
        "    if not match:\n",
        "        return 0\n",
        "\n",
        "    hours = int(match.group(1) or 0)\n",
        "    minutes = int(match.group(2) or 0)\n",
        "    seconds = int(match.group(3) or 0)\n",
        "\n",
        "    return hours * 3600 + minutes * 60 + seconds\n",
        "\n",
        "def generate_recommendations(features_dict, prediction):\n",
        "    \"\"\"Generate actionable recommendations\"\"\"\n",
        "    recommendations = []\n",
        "    warnings = []\n",
        "\n",
        "    # Title Length\n",
        "    if features_dict['title_length'] < 30:\n",
        "        warnings.append(\"‚ö†Ô∏è Title too short\")\n",
        "        recommendations.append(\"üìù **Increase title to 40-60 characters** for optimal engagement\")\n",
        "    elif features_dict['title_length'] > 70:\n",
        "        warnings.append(\"‚ö†Ô∏è Title too long\")\n",
        "        recommendations.append(\"‚úÇÔ∏è **Shorten title to 40-60 characters**\")\n",
        "    else:\n",
        "        recommendations.append(\"‚úÖ Title length is optimal!\")\n",
        "\n",
        "    # Duration\n",
        "    if features_dict['duration_seconds'] < 300:\n",
        "        warnings.append(\"‚ö†Ô∏è Video too short\")\n",
        "        recommendations.append(\"‚è±Ô∏è **Increase to 8-12 minutes** - #1 factor (26% importance)\")\n",
        "    elif features_dict['duration_seconds'] > 900:\n",
        "        warnings.append(\"‚ö†Ô∏è Video quite long\")\n",
        "        recommendations.append(\"‚è±Ô∏è **Optimal duration: 8-12 minutes**\")\n",
        "    else:\n",
        "        recommendations.append(\"‚úÖ Duration is optimal!\")\n",
        "\n",
        "    # Description\n",
        "    if features_dict['description_length'] < 150:\n",
        "        warnings.append(\"‚ö†Ô∏è Description too brief\")\n",
        "        recommendations.append(\"üìÑ **Write 200-300 words** - 19% impact on engagement\")\n",
        "    else:\n",
        "        recommendations.append(\"‚úÖ Description length is good!\")\n",
        "\n",
        "    # Tags\n",
        "    if features_dict['tags_count'] < 5:\n",
        "        warnings.append(\"‚ö†Ô∏è Not enough tags\")\n",
        "        recommendations.append(\"üè∑Ô∏è **Add 8-12 relevant tags**\")\n",
        "    else:\n",
        "        recommendations.append(\"‚úÖ Tag count is optimal!\")\n",
        "\n",
        "    # Timing\n",
        "    if features_dict['publish_hour'] < 12 or features_dict['publish_hour'] > 16:\n",
        "        recommendations.append(\"‚è∞ **Best time: 2-4 PM** (14% impact)\")\n",
        "    else:\n",
        "        recommendations.append(\"‚úÖ Publishing at optimal time!\")\n",
        "\n",
        "    # Overall\n",
        "    if prediction < 2:\n",
        "        overall = \"üî¥ **Low engagement predicted**\"\n",
        "    elif prediction < 4:\n",
        "        overall = \"üü° **Moderate engagement expected**\"\n",
        "    else:\n",
        "        overall = \"üü¢ **High engagement predicted!**\"\n",
        "\n",
        "    return overall, recommendations, warnings\n",
        "\n",
        "# ============================================================================\n",
        "# PREDICTION FUNCTIONS FOR GRADIO\n",
        "# ============================================================================\n",
        "\n",
        "def predict_from_features(title_length, description_length, tags_count,\n",
        "                         duration_minutes, publish_hour, publish_day):\n",
        "    \"\"\"Make prediction from manual input\"\"\"\n",
        "\n",
        "    duration_seconds = duration_minutes * 60\n",
        "    has_thumbnail = 1\n",
        "\n",
        "    features = [title_length, description_length, tags_count,\n",
        "                duration_seconds, publish_hour, publish_day, has_thumbnail]\n",
        "\n",
        "    # Use YOUR trained model\n",
        "    prediction = model.predict([features])[0]\n",
        "\n",
        "    features_dict = {\n",
        "        'title_length': title_length,\n",
        "        'description_length': description_length,\n",
        "        'tags_count': tags_count,\n",
        "        'duration_seconds': duration_seconds,\n",
        "        'publish_hour': publish_hour,\n",
        "        'publish_day': publish_day\n",
        "    }\n",
        "\n",
        "    overall, recommendations, warnings = generate_recommendations(features_dict, prediction)\n",
        "\n",
        "    # Format output\n",
        "    output = f\"\"\"\n",
        "# üéØ Engagement Prediction Results\n",
        "\n",
        "## Predicted Engagement Rate: **{prediction:.2f}%**\n",
        "\n",
        "{overall}\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Your Video Stats:\n",
        "- **Title**: {title_length} characters\n",
        "- **Description**: {description_length} characters\n",
        "- **Tags**: {tags_count} tags\n",
        "- **Duration**: {duration_minutes} minutes\n",
        "- **Upload**: {publish_hour}:00 on {['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'][publish_day]}\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Recommendations:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    for rec in recommendations:\n",
        "        output += f\"{rec}\\n\\n\"\n",
        "\n",
        "    if warnings:\n",
        "        output += \"\\n## ‚ö†Ô∏è Areas to Improve:\\n\\n\"\n",
        "        for warn in warnings:\n",
        "            output += f\"{warn}\\n\\n\"\n",
        "\n",
        "    output += f\"\"\"\n",
        "---\n",
        "\n",
        "## üìà Expected Performance (for 10K views):\n",
        "- **Engagement**: ~{int(prediction * 100)} likes + comments\n",
        "- **Model Confidence**: R¬≤ = {MODEL_METRICS['r2']:.1%}\n",
        "\"\"\"\n",
        "\n",
        "    return output\n",
        "\n",
        "def predict_from_url(youtube_url, api_key):\n",
        "    \"\"\"Analyze existing YouTube video\"\"\"\n",
        "\n",
        "    if not youtube_url:\n",
        "        return \"‚ùå Please enter a YouTube URL\"\n",
        "\n",
        "    video_id = parse_youtube_url(youtube_url)\n",
        "    if not video_id:\n",
        "        return \"‚ùå Invalid YouTube URL\"\n",
        "\n",
        "    if not api_key:\n",
        "        return \"‚ùå Please enter your YouTube API key\"\n",
        "\n",
        "    video_data = get_video_data_from_api(video_id, api_key)\n",
        "\n",
        "    if not video_data:\n",
        "        return \"‚ùå Could not fetch video. Check API key and URL.\"\n",
        "\n",
        "    # Extract features using YOUR FeatureEngineer logic\n",
        "    snippet = video_data['snippet']\n",
        "    stats = video_data['statistics']\n",
        "    content = video_data['contentDetails']\n",
        "\n",
        "    title_length = len(snippet['title'])\n",
        "    description_length = len(snippet.get('description', ''))\n",
        "    tags_count = len(snippet.get('tags', []))\n",
        "    duration_seconds = parse_duration(content['duration'])\n",
        "\n",
        "    publish_time = pd.to_datetime(snippet['publishedAt'])\n",
        "    publish_hour = publish_time.hour\n",
        "    publish_day = publish_time.weekday()\n",
        "\n",
        "    # Actual metrics\n",
        "    actual_views = int(stats.get('viewCount', 0))\n",
        "    actual_likes = int(stats.get('likeCount', 0))\n",
        "    actual_comments = int(stats.get('commentCount', 0))\n",
        "    actual_engagement = (actual_likes + actual_comments) / max(actual_views, 1) * 100\n",
        "\n",
        "    # Predict using YOUR model\n",
        "    features = [title_length, description_length, tags_count,\n",
        "                duration_seconds, publish_hour, publish_day, 1]\n",
        "\n",
        "    prediction = model.predict([features])[0]\n",
        "\n",
        "    features_dict = {\n",
        "        'title_length': title_length,\n",
        "        'description_length': description_length,\n",
        "        'tags_count': tags_count,\n",
        "        'duration_seconds': duration_seconds,\n",
        "        'publish_hour': publish_hour,\n",
        "        'publish_day': publish_day\n",
        "    }\n",
        "\n",
        "    overall, recommendations, warnings = generate_recommendations(features_dict, prediction)\n",
        "\n",
        "    output = f\"\"\"\n",
        "# üì∫ Video Analysis: {snippet['title']}\n",
        "\n",
        "## üéØ Engagement Analysis\n",
        "\n",
        "### Predicted: **{prediction:.2f}%** | Actual: **{actual_engagement:.2f}%**\n",
        "\n",
        "**Accuracy**: {100 - abs(prediction - actual_engagement) * 10:.1f}%\n",
        "\n",
        "{overall}\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Actual Statistics:\n",
        "- **Views**: {actual_views:,}\n",
        "- **Likes**: {actual_likes:,}\n",
        "- **Comments**: {actual_comments:,}\n",
        "- **Channel**: {snippet['channelTitle']}\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Content Details:\n",
        "- **Title**: {title_length} chars\n",
        "- **Description**: {description_length} chars\n",
        "- **Tags**: {tags_count}\n",
        "- **Duration**: {duration_seconds // 60}m {duration_seconds % 60}s\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Recommendations:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    for rec in recommendations:\n",
        "        output += f\"{rec}\\n\\n\"\n",
        "\n",
        "    if warnings:\n",
        "        output += \"\\n## ‚ö†Ô∏è Improvement Areas:\\n\\n\"\n",
        "        for warn in warnings:\n",
        "            output += f\"{warn}\\n\\n\"\n",
        "\n",
        "    return output\n",
        "\n",
        "# ============================================================================\n",
        "# VISUALIZATION FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def create_feature_importance_chart():\n",
        "    \"\"\"Feature importance bar chart\"\"\"\n",
        "\n",
        "    features = list(FEATURE_IMPORTANCE.keys())\n",
        "    importance = list(FEATURE_IMPORTANCE.values())\n",
        "\n",
        "    fig = go.Figure(data=[\n",
        "        go.Bar(\n",
        "            x=importance,\n",
        "            y=features,\n",
        "            orientation='h',\n",
        "            marker=dict(color=importance, colorscale='Viridis'),\n",
        "            text=[f'{val:.1%}' for val in importance],\n",
        "            textposition='auto',\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='üéØ Feature Importance',\n",
        "        xaxis_title='Importance',\n",
        "        height=400,\n",
        "        template='plotly_white'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def create_metrics_dashboard():\n",
        "    \"\"\"Model performance gauges\"\"\"\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # MAE gauge\n",
        "    fig.add_trace(go.Indicator(\n",
        "        mode=\"gauge+number\",\n",
        "        value=MODEL_METRICS['mae'],\n",
        "        domain={'x': [0, 0.45], 'y': [0, 1]},\n",
        "        title={'text': \"MAE\"},\n",
        "        gauge={\n",
        "            'axis': {'range': [None, 3]},\n",
        "            'bar': {'color': \"darkblue\"},\n",
        "            'steps': [\n",
        "                {'range': [0, 1], 'color': \"lightgreen\"},\n",
        "                {'range': [1, 2], 'color': \"yellow\"},\n",
        "                {'range': [2, 3], 'color': \"lightcoral\"}\n",
        "            ]\n",
        "        }\n",
        "    ))\n",
        "\n",
        "    # R¬≤ gauge\n",
        "    fig.add_trace(go.Indicator(\n",
        "        mode=\"gauge+number\",\n",
        "        value=MODEL_METRICS['r2'] * 100,\n",
        "        domain={'x': [0.55, 1], 'y': [0, 1]},\n",
        "        title={'text': \"R¬≤ Score (%)\"},\n",
        "        gauge={\n",
        "            'axis': {'range': [0, 100]},\n",
        "            'bar': {'color': \"darkgreen\"},\n",
        "            'steps': [\n",
        "                {'range': [0, 50], 'color': \"lightcoral\"},\n",
        "                {'range': [50, 70], 'color': \"yellow\"},\n",
        "                {'range': [70, 100], 'color': \"lightgreen\"}\n",
        "            ]\n",
        "        }\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(title='üìä Model Performance', height=300, template='plotly_white')\n",
        "\n",
        "    return fig\n",
        "\n",
        "# ============================================================================\n",
        "# GRADIO INTERFACE\n",
        "# ============================================================================\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"YouTube Analytics\") as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üé¨ YouTube Content Creator Analytics\n",
        "    ### AI-Powered Engagement Prediction MLOps System\n",
        "    \"\"\")\n",
        "\n",
        "    # Tab 1: Model Performance\n",
        "    with gr.Tab(\"üìä Model Performance\"):\n",
        "        gr.Markdown(\"## Your Trained Model Metrics\")\n",
        "\n",
        "        gr.Plot(value=create_metrics_dashboard())\n",
        "        gr.Plot(value=create_feature_importance_chart())\n",
        "\n",
        "        gr.Markdown(f\"\"\"\n",
        "        ### üéØ Model Stats:\n",
        "        - **R¬≤ Score**: {MODEL_METRICS['r2']:.4f} (65% accuracy)\n",
        "        - **MAE**: {MODEL_METRICS['mae']:.4f}\n",
        "        - **Top Factor**: Video Duration (26%)\n",
        "        - **Algorithm**: Random Forest (100 trees)\n",
        "        \"\"\")\n",
        "\n",
        "    # Tab 2: Manual Prediction\n",
        "    with gr.Tab(\"üéØ Predict Engagement\"):\n",
        "        gr.Markdown(\"## Get predictions for your planned video\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                title_len = gr.Slider(10, 100, value=50, step=1, label=\"Title Length\")\n",
        "                desc_len = gr.Slider(0, 1000, value=250, step=10, label=\"Description Length\")\n",
        "                tags = gr.Slider(0, 20, value=10, step=1, label=\"Tags Count\")\n",
        "\n",
        "            with gr.Column():\n",
        "                duration = gr.Slider(1, 30, value=10, step=0.5, label=\"Duration (minutes)\")\n",
        "                pub_hour = gr.Slider(0, 23, value=15, step=1, label=\"Publish Hour\")\n",
        "                pub_day = gr.Dropdown(\n",
        "                    choices=[(day, i) for i, day in enumerate(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])],\n",
        "                    value=2,\n",
        "                    label=\"Publish Day\"\n",
        "                )\n",
        "\n",
        "        predict_btn = gr.Button(\"üöÄ Predict\", variant=\"primary\", size=\"lg\")\n",
        "        prediction_output = gr.Markdown()\n",
        "\n",
        "        predict_btn.click(\n",
        "            fn=predict_from_features,\n",
        "            inputs=[title_len, desc_len, tags, duration, pub_hour, pub_day],\n",
        "            outputs=prediction_output\n",
        "        )\n",
        "\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                [45, 250, 10, 10, 15, 2],\n",
        "                [25, 100, 3, 5, 9, 0],\n",
        "                [60, 400, 12, 12, 14, 1],\n",
        "            ],\n",
        "            inputs=[title_len, desc_len, tags, duration, pub_hour, pub_day]\n",
        "        )\n",
        "\n",
        "    # Tab 3: URL Analysis\n",
        "    with gr.Tab(\"üì∫ Analyze Video\"):\n",
        "        gr.Markdown(\"## Analyze existing YouTube videos\")\n",
        "\n",
        "        video_url = gr.Textbox(\n",
        "            label=\"YouTube URL\",\n",
        "            placeholder=\"https://www.youtube.com/watch?v=...\",\n",
        "        )\n",
        "\n",
        "        api_key_input = gr.Textbox(\n",
        "            label=\"Your API Key\",\n",
        "            placeholder=\"AIzaSy...\",\n",
        "            type=\"password\"\n",
        "        )\n",
        "\n",
        "        analyze_btn = gr.Button(\"üîç Analyze\", variant=\"primary\", size=\"lg\")\n",
        "        analysis_output = gr.Markdown()\n",
        "\n",
        "        analyze_btn.click(\n",
        "            fn=predict_from_url,\n",
        "            inputs=[video_url, api_key_input],\n",
        "            outputs=analysis_output\n",
        "        )\n",
        "\n",
        "    # Tab 4: About\n",
        "    with gr.Tab(\"‚ÑπÔ∏è About\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        # MLOps Project Details\n",
        "\n",
        "        ## üîß Pipeline:\n",
        "        1. **Data Collection**: YouTube API\n",
        "        2. **Feature Engineering**: 7 key features\n",
        "        3. **Model Training**: Random Forest\n",
        "        4. **Deployment**: Gradio interface\n",
        "\n",
        "        ## üìä Performance:\n",
        "        - R¬≤ = 0.649 (65% accuracy)\n",
        "        - MAE = 1.15 percentage points\n",
        "\n",
        "        ## üéØ Use Cases:\n",
        "        - Optimize video strategy\n",
        "        - Predict engagement before publishing\n",
        "        - A/B test video parameters\n",
        "        \"\"\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True, server_port=7860)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "8D41Yz3iLc_3",
        "outputId": "bab76174-4e4e-4925-803d-82bcc5451a6b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://91ef09f167f3d2952b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://91ef09f167f3d2952b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzF7df5wOFpA"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}
